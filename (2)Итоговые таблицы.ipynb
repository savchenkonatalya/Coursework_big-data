{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "import nltk\n",
    "import pymorphy2\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Мешки слов и предложения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baa1752cc0c149e2917b20c453aa9e25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('/Users/Downloads/Новости.xlsx')\n",
    "df_full = df.fillna('пустой_отзыв')\n",
    "texts = df_full['Текст поста']\n",
    "morf = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "tokens_sent = []\n",
    "tokens_bow = []\n",
    "\n",
    "tags_list = ['NOUN','ADJF','ADJS','VERB','INFN','ADVB']\n",
    "for text in tqdm(texts):\n",
    "    tokens_0 = nltk.word_tokenize(text)\n",
    "    tokens_1 = []\n",
    "    for token in tokens_0:\n",
    "        token_morf_inf = morf.parse(token)\n",
    "        if token_morf_inf[0].tag.POS in tags_list:\n",
    "            tokens_1.append(token_morf_inf[0].normal_form)\n",
    "\n",
    "    tokens_bow.extend(tokens_1)    \n",
    "    \n",
    "    sentence = ' '.join(tokens_1)\n",
    "    tokens_sent.append(sentence)\n",
    "    \n",
    "converter = TfidfVectorizer(max_features = 1500)\n",
    "\n",
    "pd.DataFrame(tokens_sent).to_excel('ДТП_предложения.xlsx')\n",
    "\n",
    "pd.DataFrame(dict(Counter(tokens_bow)).items()).to_excel('ДТП_мешки_слов.xlsx') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кластеры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6639ef7cf5014237bb25393f6d6b22d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "clusters_num = 20\n",
    "df = pd.DataFrame(tokens_sent)\n",
    "df_list = df[0].values.tolist()\n",
    "    \n",
    "tfidfconverter = TfidfVectorizer(max_features = 1500)\n",
    "X = tfidfconverter.fit_transform(df_list).toarray()\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components = clusters_num,\n",
    "                                learning_method = \"batch\",\n",
    "                                max_iter = 25,\n",
    "                                random_state = 0)\n",
    "document_topics = lda.fit_transform(X)\n",
    "\n",
    "sorting = np.argsort(lda.components_, axis = 1)[:, ::-1]\n",
    "feature_names = np.array(list(dict(sorted(tfidfconverter.vocabulary_.items(), key = itemgetter(1))).keys()))   \n",
    "clusters_tokens = []\n",
    "for num in tqdm(range (0, clusters_num)):\n",
    "    tokens_list = list(feature_names[list(sorting[num])])\n",
    "    clusters_tokens.append(tokens_list)   \n",
    "df_clust = pd.DataFrame(clusters_tokens).T\n",
    "\n",
    "df_clust.to_excel('ДТП_кластеры.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_norm_nums = [***] #сюда вписываем найденные кластеры, ранижруя по частоте встречания\n",
    "\n",
    "clusters_solution = []\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components = clusters_num,\n",
    "                                learning_method = \"batch\",\n",
    "                                max_iter = 25,\n",
    "                                random_state = 0)\n",
    "document_topics = lda.fit_transform(X)\n",
    "\n",
    "for marks_list in tqdm(document_topics):\n",
    "    clusters_solution.append(marks_list[clusters_norm_nums])\n",
    "y = []\n",
    "for marks_list in tqdm(clusters_solution):\n",
    "    m = list(marks_list)\n",
    "    y.append(m.index(max(m)))\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 1000, random_state = 0 )\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "scores = classifier.predict_proba(tfidfconverter.transform(df_list).toarray())\n",
    "df_lists = []\n",
    "index = 0\n",
    "for t in df_list:\n",
    "    df_lists.append(list(np.append(t,scores[index])))\n",
    "    index += 1\n",
    "\n",
    "pd.DataFrame(df_lists).to_excel('ДТП_выбранные_кластеры.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
